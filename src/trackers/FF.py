# Upload Assistant © 2025 Audionut & wastaken7 — Licensed under UAPL v1.0
import asyncio
import glob
import os
import platform
import re
from typing import Any, Optional, Union, cast

import aiofiles
import httpx
from bs4 import BeautifulSoup

from src.bbcode import BBCODE
from src.console import console
from src.cookie_auth import CookieAuthUploader, CookieValidator
from src.get_desc import DescriptionBuilder
from src.languages import languages_manager


class FF:
    def __init__(self, config: dict[str, Any]) -> None:
        self.config = config
        self.cookie_validator = CookieValidator(config)
        self.cookie_auth_uploader = CookieAuthUploader(config)
        self.tracker = "FF"
        self.banned_groups: list[str] = []
        self.source_flag = "FunFile"
        self.base_url = "https://www.funfile.org"
        self.torrent_url = f"{self.base_url}/details.php?id="
        self.requests_url = f"{self.base_url}/requests.php"
        self.auth_token = None
        self.session = httpx.AsyncClient(headers={
            'User-Agent': f"Upload Assistant/2.3 ({platform.system()} {platform.release()})"
        }, timeout=30.0)

    async def validate_credentials(self, meta: dict[str, Any]) -> bool:
        cookie_file = os.path.abspath(f"{meta['base_dir']}/data/cookies/{self.tracker}.txt")
        if not os.path.exists(cookie_file):
            await self.login(meta)

        cookie_jar = await self.cookie_validator.load_session_cookies(meta, self.tracker)
        if cookie_jar is None:
            return False
        self.session.cookies = cookie_jar
        valid_cookies = await self.validate_cookies(meta)
        if valid_cookies:
            return True
        else:
            await self.login(meta)
            return await self.validate_cookies(meta)

    async def validate_cookies(self, meta: dict[str, Any]) -> bool:
        return await self.cookie_validator.cookie_validation(
            meta=meta,
            tracker=self.tracker,
            test_url=f'{self.base_url}/upload.php',
            success_text='friends.php',
        )

    async def login(self, meta: dict[str, Any]) -> None:
        login_url = "https://www.funfile.org/takelogin.php"
        cookie_file = os.path.abspath(f"{meta['base_dir']}/data/cookies/{self.tracker}.txt")

        payload = {
            "returnto": "/index.php",
            "username": self.config['TRACKERS'][self.tracker]['username'],
            "password": self.config['TRACKERS'][self.tracker]['password'],
            "login": "Login"
        }

        console.print(f"{self.tracker}: Trying to login...", markup=False)
        response = await self.session.post(login_url, data=payload)

        if response.status_code == 302:
            console.print(f"{self.tracker}: Login Successful!", markup=False)

            async with aiofiles.open(cookie_file, "w") as f:
                await f.write("# Netscape HTTP Cookie File\n")
                await f.write("# This file was generated by an automated script.\n\n")
                for cookie in self.session.cookies.jar:
                    domain = cookie.domain
                    include_subdomains = "TRUE" if domain.startswith('.') else "FALSE"
                    path = cookie.path
                    secure = "TRUE" if cookie.secure else "FALSE"
                    expires = str(int(cookie.expires)) if cookie.expires else "0"
                    name = cookie.name
                    value = cookie.value
                    await f.write(f"{domain}\t{include_subdomains}\t{path}\t{secure}\t{expires}\t{name}\t{value}\n")
            console.print(f"{self.tracker}: Saving the cookie file...", markup=False)
        else:
            console.print(f"{self.tracker}: Login failed. Status code: {response.status_code}", markup=False)

    async def search_existing(self, meta: dict[str, Any], _disctype: str) -> list[str]:
        cookie_jar = await self.cookie_validator.load_session_cookies(meta, self.tracker)
        if cookie_jar is None:
            return []
        self.session.cookies = cookie_jar

        query = meta['title']
        if meta['category'] == 'TV':
            query = f"{meta['title']} {meta.get('season', '')}{meta.get('episode', '')}"

        search_url = f"{self.base_url}/suggest.php?q={query}"
        response = await self.session.get(search_url)

        if response.status_code == 200 and 'login' not in str(response.url):
            items = [line.strip() for line in response.text.splitlines() if line.strip()]
            return items

        return []

    async def get_requests(self, meta: dict[str, Any]) -> Union[bool, list[dict[str, str]]]:
        if self.config['TRACKERS'][self.tracker].get('check_requests', False) is False:
            return False

        else:
            try:
                cookie_jar = await self.cookie_validator.load_session_cookies(meta, self.tracker)
                if cookie_jar is None:
                    return []
                self.session.cookies = cookie_jar
                category = self.get_type_id(meta)

                query_1 = meta['title']
                query_2 = meta['title'].replace(' ', '.')

                search_url_1 = f"{self.requests_url}?filter=open&category={category}&search={query_1}"

                if query_1 != query_2:
                    search_url_2 = f"{self.base_url}/requests.php?filter=open&category={category}&search={query_2}"
                    responses = await asyncio.gather(
                        self.session.get(search_url_1),
                        self.session.get(search_url_2)
                    )
                    response_results_text = responses[0].text + responses[1].text
                    responses[0].raise_for_status()
                    responses[1].raise_for_status()
                else:
                    response = await self.session.get(search_url_1)
                    response.raise_for_status()
                    response_results_text = response.text

                soup = BeautifulSoup(response_results_text, "html.parser")
                request_rows = soup.select("td.mf_content table tr")

                results: list[dict[str, str]] = []
                for row in request_rows:
                    name_element = row.select_one("td.row3 nobr a b")
                    if not name_element:
                        continue

                    name = name_element.text.strip()
                    link_element = name_element.find_parent("a")
                    link = str(link_element["href"]) if link_element and link_element.has_attr("href") else ""

                    all_tds = row.find_all("td", class_="row3")
                    reward = all_tds[2].text.strip() if len(all_tds) > 2 else ""

                    results.append({
                        "Name": name,
                        "Link": link,
                        "Reward": reward
                    })

                if results:
                    message = f"\n{self.tracker}: [bold yellow]Your upload may fulfill the following request(s), check it out:[/bold yellow]\n\n"
                    for r in results:
                        message += f"[bold green]Name:[/bold green] {r['Name']}\n"
                        message += f"[bold green]Reward:[/bold green] {r['Reward']}\n"
                        message += f"[bold green]Link:[/bold green] {r['Link']}\n\n"
                    console.print(message)

                return results

            except Exception as e:
                console.print(f"An error occurred while fetching requests: {e}", markup=False)
                return []

    async def generate_description(self, meta: dict[str, Any]) -> str:
        builder = DescriptionBuilder(self.tracker, self.config)
        desc_parts: list[str] = []

        # Custom Header
        desc_parts.append(await builder.get_custom_header())

        # Logo
        logo_resize_url = meta.get('tmdb_logo', '')
        if logo_resize_url:
            desc_parts.append(f"[center][img]https://image.tmdb.org/t/p/w300/{logo_resize_url}[/img][/center]")

        # TV
        title, episode_image, episode_overview = await builder.get_tv_info(meta)
        if episode_overview:
            desc_parts.append(f'[center]{title}[/center]')

            if episode_image:
                desc_parts.append(f'[center]<a href="{episode_image}" target="_blank"><img src="{episode_image}" width="220"></a>[/center]')

            desc_parts.append(f'[center]{episode_overview}[/center]')

        # File information
        mediainfo = await builder.get_mediainfo_section(meta)
        if mediainfo:
            desc_parts.append(f'[pre]{mediainfo}[/pre]')

        bdinfo = await builder.get_bdinfo_section(meta)
        if bdinfo:
            desc_parts.append(f'[pre]{bdinfo}[/pre]')

        # User description
        desc_parts.append(await builder.get_user_description(meta))

        # Disc menus screenshots header
        desc_parts.append(await builder.menu_screenshot_header(meta))

        # Disc menus screenshots
        menu_images = meta.get("menu_images", [])
        if isinstance(menu_images, list) and menu_images:
            menu_screenshots_block = ""
            menu_images_list = cast(list[Any], menu_images)
            for image in menu_images_list:
                if not isinstance(image, dict):
                    continue
                image_dict = cast(dict[str, Any], image)
                menu_img_url = image_dict.get("img_url")
                menu_web_url = image_dict.get("web_url")
                if isinstance(menu_img_url, str) and isinstance(menu_web_url, str) and menu_img_url and menu_web_url:
                    menu_screenshots_block += f'<a href="{menu_web_url}" target="_blank"><img src="{menu_img_url}" width="220"></a> '
            if menu_screenshots_block:
                desc_parts.append(f"[center]{menu_screenshots_block}[/center]")

        # Tonemapped Header
        desc_parts.append(await builder.get_tonemapped_header(meta))

        # Screenshot Header
        images = meta.get("image_list", [])
        if isinstance(images, list) and images:
            desc_parts.append(await builder.screenshot_header())

            # Screenshots
            screenshots_block = ""
            images_list = cast(list[Any], images)
            for image in images_list:
                if not isinstance(image, dict):
                    continue
                image_dict = cast(dict[str, Any], image)
                img_url = image_dict.get("img_url")
                web_url = image_dict.get("web_url")
                if isinstance(img_url, str) and isinstance(web_url, str) and img_url and web_url:
                    screenshots_block += (
                        f'<a href="{web_url}" target="_blank"><img src="{img_url}" width="220"></a> '
                    )
            if screenshots_block:
                desc_parts.append(f"[center]{screenshots_block}[/center]")

        # Signature
        desc_parts.append(f"[url=https://github.com/yippee0903/Upload-Assistant][center][size=1]{meta['ua_signature']}[/size][/center][/url]")

        description = '\n\n'.join(part for part in desc_parts if part.strip())

        bbcode = BBCODE()
        description = description.replace("[user]", "").replace("[/user]", "")
        description = description.replace("[align=left]", "").replace("[/align]", "")
        description = description.replace("[right]", "").replace("[/right]", "")
        description = description.replace("[align=right]", "").replace("[/align]", "")
        description = bbcode.remove_sub(description)
        description = bbcode.remove_sup(description)
        description = description.replace("[alert]", "").replace("[/alert]", "")
        description = description.replace("[note]", "").replace("[/note]", "")
        description = description.replace("[hr]", "").replace("[/hr]", "")
        description = description.replace("[h1]", "[u][b]").replace("[/h1]", "[/b][/u]")
        description = description.replace("[h2]", "[u][b]").replace("[/h2]", "[/b][/u]")
        description = description.replace("[h3]", "[u][b]").replace("[/h3]", "[/b][/u]")
        description = description.replace("[ul]", "").replace("[/ul]", "")
        description = description.replace("[ol]", "").replace("[/ol]", "")
        description = description.replace("[hide]", "").replace("[/hide]", "")
        description = description.replace("•", "-").replace("“", '"').replace("”", '"')
        description = bbcode.convert_comparison_to_centered(description, 1000)
        description = bbcode.remove_spoiler(description)

        # [url][img=000]...[/img][/url]
        description = re.sub(
            r"\[url=(?P<href>[^\]]+)\]\[img=(?P<width>\d+)\](?P<src>[^\[]+)\[/img\]\[/url\]",
            r'<a href="\g<href>" target="_blank"><img src="\g<src>" width="\g<width>"></a>',
            description,
            flags=re.IGNORECASE
        )

        # [url][img]...[/img][/url]
        description = re.sub(
            r"\[url=(?P<href>[^\]]+)\]\[img\](?P<src>[^\[]+)\[/img\]\[/url\]",
            r'<a href="\g<href>" target="_blank"><img src="\g<src>" width="220"></a>',
            description,
            flags=re.IGNORECASE
        )

        # [img=200]...[/img] (no [url])
        description = re.sub(
            r"\[img=(?P<width>\d+)\](?P<src>[^\[]+)\[/img\]",
            r'<img src="\g<src>" width="\g<width>">',
            description,
            flags=re.IGNORECASE
        )

        description = bbcode.remove_extra_lines(description)

        async with aiofiles.open(
            f"{meta['base_dir']}/tmp/{meta['uuid']}/[{self.tracker}]DESCRIPTION.txt", 'w', encoding='utf-8'
        ) as description_file:
            await description_file.write(description)

        return description

    def get_type_id(self, meta: dict[str, Any]) -> str:
        if meta.get('anime'):
            return '44'
        category = meta['category']

        if category == 'MOVIE':
            return '19'

        elif category == 'TV':
            return '7'

        return '19'

    def file_information(self, meta: dict[str, Any]) -> None:
        vc = meta.get('video_codec', '')
        if vc:
            self.video_codec = vc.strip().lower()

        ve = meta.get('video_encode', '')
        if ve:
            self.video_encode = ve.strip().lower()

        vs = meta.get('source', '')
        if vs:
            self.video_source = vs.strip().lower()

        vt = meta.get('type', '')
        if vt:
            self.video_type = vt.strip().lower()

    def movie_type(self, _meta: dict[str, Any]) -> str:
        # Possible values: "XviD", "DVDR", "x264", "x265", "MP4", "VCD"
        if self.video_source == 'dvd':
            return "DVDR"

        if self.video_codec == 'hevc':
            return "x265"
        else:
            return "x264"

    def tv_type(self, meta: dict[str, Any]) -> str:
        # Possible values: "XviD", "HR-XviD", "x264-SD", "x264-HD", "x265-SD", "x265-HD", "Web-SD", "Web-HD", "DVDR", "MP4"
        if self.video_source == 'dvd':
            return "DVDR"

        if self.video_source == 'web':
            if meta.get('sd'):
                return "Web-SD"
            else:
                return "Web-HD"

        if self.video_codec == 'hevc':
            if meta.get('sd'):
                return "x265-SD"
            else:
                return "x265-HD"
        else:
            if meta.get('sd'):
                return "x264-SD"
            else:
                return "x264-HD"

    def anime_type(self, meta: dict[str, Any]) -> str:
        # Possible values: "TVSeries", "TVSpecial", "Movie", "OVA", "ONA", "DVDSpecial"
        if meta.get('tvmaze_episode_data', {}).get('season_number') == 0:
            return "TVSpecial"

        if self.video_source == 'dvd':
            return "DVDSpecial"

        category = meta['category']

        if category == 'TV':
            return "TVSeries"

        if category == 'MOVIE':
            return "Movie"

        return "TVSeries"

    def movie_source(self, _meta: dict[str, Any]) -> Optional[str]:
        # Possible values: "DVD", "DVDSCR", "Workprint", "TeleCine", "TeleSync", "CAM", "BluRay", "HD-DVD", "HDTV", "R5", "WebRIP"
        mapping = {
            "dvd": "DVD",
            "dvdscr": "DVDSCR",
            "workprint": "Workprint",
            "telecine": "TeleCine",
            "telesync": "TeleSync",
            "cam": "CAM",
            "bluray": "BluRay",
            "blu-ray": "BluRay",
            "hd-dvd": "HD-DVD",
            "hdtv": "HDTV",
            "r5": "R5",
            "web": "WebRIP",
            "webrip": "WebRIP"
        }

        src = (self.video_source or "").strip().lower()
        return mapping.get(src)

    def tv_source(self, _meta: dict[str, Any]) -> Optional[str]:
        # Possible values: "HDTV", "DSR", "PDTV", "TV", "DVD", "DvdScr", "BluRay", "WebRIP"
        mapping = {
            "hdtv": "HDTV",
            "dsr": "DSR",
            "pdtv": "PDTV",
            "tv": "TV",
            "dvd": "DVD",
            "dvdscr": "DvdScr",
            "bluray": "BluRay",
            "blu-ray": "BluRay",
            "web": "WebRIP",
            "webrip": "WebRIP"
        }

        src = (self.video_source or "").strip().lower()
        return mapping.get(src)

    def anime_source(self, _meta: dict[str, Any]) -> Optional[str]:
        # Possible values: "DVD", "BluRay", "Anime Series", "HDTV"
        mapping = {
            "hdtv": "HDTV",
            "tv": "HDTV",
            "dvd": "DVD",
            "bluray": "BluRay",
            "blu-ray": "BluRay",
            "web": "Anime Series",
            "webrip": "Anime Series"
        }

        src = (self.video_source or "").strip().lower()
        return mapping.get(src)

    def anime_v_dar(self, meta: dict[str, Any]) -> str:
        # Possible values: "16_9", "4_3"
        if meta.get('is_disc') != "BDMV":
            tracks = meta.get('mediainfo', {}).get('media', {}).get('track', [])
            for track in tracks:
                if track.get('@type') == "Video":
                    dar_str = track.get('DisplayAspectRatio')
                    if dar_str:
                        try:
                            dar = float(dar_str)
                            return "16_9" if dar > 1.34 else "4_3"
                        except (ValueError, TypeError):
                            return "16_9"

            return "16_9"
        else:
            return "16_9"

    def anime_v_codec(self, _meta: dict[str, Any]) -> str:
        # Possible values: "x264", "h264", "XviD", "DivX", "WMV", "VC1"
        if self.video_codec == 'vc-1':
            return "VC1"

        if self.video_encode == 'h.264':
            return "h264"
        else:
            return 'x264'

    async def edit_name(self, meta: dict[str, Any]) -> str:
        if meta.get("scene", False):
            if meta.get("scene_name", ""):
                ff_name = str(meta.get("scene_name"))
            else:
                ff_name = str(meta["uuid"])
                base, ext = os.path.splitext(ff_name)
                if ext.lower() in {".mkv", ".mp4", ".avi", ".ts"}:
                    ff_name = base.replace(" ", ".")
        else:
            ff_name = meta.get("clean_name", "").replace(" ", ".")

        return ff_name

    async def languages(self, meta: dict[str, Any]) -> dict[str, list[str]]:
        if not meta.get('language_checked', False):
            await languages_manager.process_desc_language(meta, tracker=self.tracker)

        lang_map = {
            'english': 'en',
            'japanese': 'jp',
            'korean': 'kr',
            'thai': 'th',
            'chinese': 'zh',
        }

        anime_a_codec: list[str] = []
        anime_a_ch: list[str] = []
        anime_a_lang: list[str] = []

        anime_s_format: list[str] = []
        anime_s_type: list[str] = []
        anime_s_lang: list[str] = []

        audio_languages = meta.get('audio_languages', [])
        if isinstance(audio_languages, list) and audio_languages:
            audio_desc = meta.get('audio', '').lower()
            found_codec = '0'
            codec_options = {
                'aac': 'aac', 'ac3': 'ac3', 'dd': 'ac3', 'dolby digital': 'ac3', 'ogg': 'ogg', 'mp3': 'mp3',
                'dts-es': 'dtses', 'dtses': 'dtses', 'dts': 'dts', 'flac': 'flac', 'pcm': 'pcm', 'wma': 'wma'
            }
            for key, value in codec_options.items():
                if key in audio_desc:
                    found_codec = value
                    break

            channels_desc = meta.get('channels', '')
            channel_map = {
                '2.0': '2',
                '5.1': '5_1',
                '7.1': '7_1'
            }
            found_channel = channel_map.get(channels_desc, '0')

            audio_languages_list = cast(list[Any], audio_languages)
            for lang_str in audio_languages_list:
                lang_code = lang_map.get(str(lang_str).lower(), '1')

                anime_a_codec.append(found_codec)
                anime_a_ch.append(found_channel)
                anime_a_lang.append(lang_code)

        subtitle_languages = meta.get('subtitle_languages', [])
        if isinstance(subtitle_languages, list) and subtitle_languages:
            subtitle_format = 'srt'
            subtitle_type = 'sub'

            subtitle_languages_list = cast(list[Any], subtitle_languages)
            for lang_str in subtitle_languages_list:
                lang_code = lang_map.get(str(lang_str).lower(), '1')

                anime_s_format.append(subtitle_format)
                anime_s_type.append(subtitle_type)
                anime_s_lang.append(lang_code)

        return {
            'anime_a_codec': anime_a_codec,
            'anime_a_ch': anime_a_ch,
            'anime_a_lang': anime_a_lang,
            'anime_s_format': anime_s_format,
            'anime_s_type': anime_s_type,
            'anime_s_lang': anime_s_lang,
        }

    async def get_poster(self, meta: dict[str, Any]) -> Optional[tuple[str, bytes, str]]:
        poster_url = meta.get('poster')

        poster_file = None
        if poster_url:
            async with httpx.AsyncClient() as client:
                response = await client.get(poster_url)
                if response.status_code == 200:
                    poster_ext = os.path.splitext(poster_url)[1] or ".jpg"
                    poster_filename = f"{meta.get('name')}{poster_ext}"
                    poster_file = (poster_filename, response.content, "image/jpeg")

                    return poster_file

        return None

    def get_nfo(self, meta: dict[str, Any]) -> dict[str, tuple[str, Any, str]]:
        nfo_dir = os.path.join(meta['base_dir'], "tmp", meta['uuid'])
        nfo_files = glob.glob(os.path.join(nfo_dir, "*.nfo"))

        if nfo_files:
            nfo_path = nfo_files[0]

            return {
                'nfo': (
                    os.path.basename(nfo_path),
                    open(nfo_path, "rb"),
                    "application/octet-stream"
                )
            }
        return {}

    async def get_data(self, meta: dict[str, Any]) -> dict[str, Any]:
        languages = await self.languages(meta)
        self.file_information(meta)

        data: dict[str, Any] = {
            'MAX_FILE_SIZE': 10000000,
            'type': self.get_type_id(meta),
            'tags': '',
            'descr': await self.generate_description(meta),
        }

        if meta.get('anime'):
            data.update({
                'anime_type': self.anime_type(meta),
                'anime_source': self.anime_source(meta),
                'anime_container': 'mkv',
                'anime_v_res': meta.get('resolution'),
                'anime_v_dar': self.anime_v_dar(meta),
                'anime_v_codec': self.anime_v_codec(meta),
                'anime_a_codec[]': ['0'] + languages.get('anime_a_codec', []),
                'anime_a_ch[]': ['0'] + languages.get('anime_a_ch', []),
                'anime_a_lang[]': ['0'] + languages.get('anime_a_lang', []),
                'anime_s_format[]': ['0'] + languages.get('anime_s_format', []),
                'anime_s_type[]': ['0'] + languages.get('anime_s_type', []),
                'anime_s_lang[]': ['0'] + languages.get('anime_s_lang', []),
            })

        else:
            if meta['category'] == 'MOVIE':
                data.update({
                    'movie_type': self.movie_type(meta),
                    'movie_source': self.movie_source(meta),
                    'movie_imdb': str(meta.get('imdb_info', {}).get('imdb_url', '')),
                    'pack': 0,
                })

            if meta['category'] == 'TV':
                data.update({
                    'tv_type': self.tv_type(meta),
                    'tv_source': self.tv_source(meta),
                    'tv_imdb': str(meta.get('imdb_info', {}).get('imdb_url', '')),
                    'pack': 1 if meta.get('tv_pack', 0) else 0,
                })

        return data

    async def upload(self, meta: dict[str, Any], _disctype: str) -> bool:
        cookie_jar = await self.cookie_validator.load_session_cookies(meta, self.tracker)
        if cookie_jar is None:
            return False
        self.session.cookies = cookie_jar
        data = await self.get_data(meta)
        torrent_name = await self.edit_name(meta)
        files: dict[str, Any] = {}
        poster = await self.get_poster(meta)
        if poster:
            files['poster'] = poster
        nfo = self.get_nfo(meta)
        if nfo:
            files['nfo'] = nfo['nfo']

        is_uploaded = await self.cookie_auth_uploader.handle_upload(
            meta=meta,
            tracker=self.tracker,
            source_flag=self.source_flag,
            torrent_url=self.torrent_url,
            data=data,
            torrent_field_name='file',
            torrent_name=torrent_name,
            upload_cookies=self.session.cookies,
            upload_url=f"{self.base_url}/takeupload.php",
            id_pattern=r'details\.php\?id=(\d+)',
            success_status_code="302",
            additional_files=files
        )

        return is_uploaded
